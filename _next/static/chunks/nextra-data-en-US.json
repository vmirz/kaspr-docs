{"/docs/api-reference/v1alpha1":{"title":"API Reference","data":{"resources-types#Resources Types":"KasprApp\nKasprAgent\nKasprTask\nKasprWebView","kasprapp#KasprApp":"A program that runs components of a distributed stream processing application.","kasprappspec#KasprAppSpec":"Specification of the desired settings of the application.","kasprappconfig#KasprAppConfig":"KasprApp configuration parameters.","kaspragent#KasprAgent":"A distributed system processing events in a stream.","kaspragentspec#KasprAgentSpec":"Specification of the desired behavior of the KasprAgent.","kaspragentinput#KasprAgentInput":"Input configuration for the KasprAgent.","kaspragentinputtopic#KasprAgentInputTopic":"Input topic configuration for the KasprAgent.","kaspragentinputchannel#KasprAgentInputChannel":"Input channel configuration for the KasprAgent.","kaspragentinputbuffer#KasprAgentInputBuffer":"Buffering configuration for the input. This allows the agent to collect multiple events before processing them.","kaspragentoutput#KasprAgentOutput":"Output configuration for the KasprAgent.","kaspragentoutputtopic#KasprAgentOutputTopic":"Output topic configuration for the KasprAgent.","code#Code":"Injectable custom code that is used achieve a desired outcome in a specific context.","kaspragentprocessors#KasprAgentProcessors":"Chain of processors that modify input values.","kaspragentprocessoroperation#KasprAgentProcessorOperation":"A transform or action to take on input events.","kaspragentprocessoroperationtable#KasprAgentProcessorOperationTable":"Reference to a KasprTable and how it is made available to an operation's function.","kasprwebview#KasprWebView":"A web view provides an HTTP endpoint to a KasprApp, enabling remote access to the application.","kasprwebviewrequest#KasprWebViewRequest":"Specification for the web view request endpoint.","kasprwebviewresponse#KasprWebViewResponse":"Specification for the web view's response output.","kasprwebviewresulthandler#KasprWebViewResultHandler":"Function handlers for success or error.","kafkaauthentication#KafkaAuthentication":"Kafka authentication configuration.","passwordsecret#PasswordSecret":"Kubernetes secret.","storagerequirements#StorageRequirements":"Disk storage configuration (disk)."}},"/docs/copyright":{"title":"Copyright","data":{"":"Kaspr Documentation (Copyright 2024-2025)Portions of this documentation are derived and adapted from the original Faust User Manual by Robinhood Markets, Inc.This material may be copied or distributed only subject to the terms and conditions set forth in the Creative Commons Attribution-ShareAlike 4.0 International http://creativecommons.org/licenses/by-sa/4.0/legalcode license.You may share and adapt the material, even for commercial purposes, but you must give the original author credit. If you alter, transform, or build upon this work, you may distribute the resulting work only under the same license or a license compatible to this one.Note:\nWhile the Kaspr documentation is offered under the Creative Commons Attribution-ShareAlike 4.0 International license the Kaspr software is offered under the BSD License (3 Clause)"}},"/docs/getting-started/architecture":{"title":"Architecture","data":{}},"/docs/getting-started/installation":{"title":"Installation","data":{"":"Learn how to install Kaspr Operator in a Kubernetes cluster."}},"/docs/getting-started/installation/helm":{"title":"Install with Helm","data":{"":"Use helm to install and manage kaspr-operator and related CRDs in your Kubernetes cluster.","prerequisites#Prerequisites":"Kubernetes 1.16+\nHelm 3.x","installation-modes#Installation Modes":"The Kaspr Operator can be installed in either cluster-scoped or namespace-scoped mode.\nWhen installed in cluster-scoped mode, the operator will watch for Kaspr resources across all namespaces.\nWhen installed in namespace-scoped mode, the operator will only watch for Kaspr resources in the same namespace where the operator is installed.\nBy default, the operator is installed in cluster-scoped mode. To install the operator in namespace-scoped mode, set the watchAnyNamespace option to false.Depending on which mode is used, either the ClusterRole or Role and ClusterRoleBinding or RoleBinding resources are created respectively.","installation-steps#Installation Steps":"","download-the-helm-chart#Download the helm chart":"git clone https://github.com/totalwinelabs/kaspr-helm.git\ncd kaspr-helm","install-the-operator#Install the operator":"The general syntax for helm installation is:\nhelm install <release> <chart> --namespace <namespace> --create-namespace [--set <other_parameters>]\nThe variables specified in the command are as follows:\n<chart> A path to a packaged chart, a path to an unpacked chart directory or a URL.\n<release> A name to identify and manage the Helm chart once installed.\n<namespace> The namespace in which the chart is to be installed.\nDefault configuration values can be changed using one or more --set <parameter>=<value> arguments. Alternatively, you can specify several parameters in a custom values file using the --values <file> argument.\nhelm install kaspr-operator charts/operator \\\n    --set operator.watchAnyNamespace=true \\\n    -n kaspr-operator \\\n    --create-namespace\nThis will install the operator in a dedicated kaspr-operator namespace using default options\nwhich is sufficient for most deployments. However, you can override options to customize the\ndeployment according to your needs. See values.yaml\nfor all possible configuration options.","custom-resource-definitions-crds#Custom Resource Definitions (CRDs)":"CRDs are included in the operator helm chart and will be automatically installed with the operator.\nHowever, they need to be manually updated or removed when necessary.\nUpdating CRDs\nkubectl apply -f ./charts/operator/crds\nDeleting CRDs\nkubectl delete -f ./charts/operator/crds","uninstall-the-operator#Uninstall the Operator":"helm uninstall kaspr-operator -n kaspr-operator\nHelm will not delete Kaspr CRDs. You will need to manually delete these if necessary."}},"/docs/getting-started/introduction":{"title":"Introduction","data":{"how-it-works#How it works":"","agents#Agents":"Process infinite streams in a straightforward manner. The concept of “agents” comes from the actor model, and means the stream processor can execute concurrently on on hundreds of machines at the same time.Deploy an agent using a Kubernetes resource and assign it to an app. Use regular Python or your favorite python libraries to customize stream processing logic and behavior.TODO: Update this example\napiVersion: kaspr.io/v1alpha1\nkind: KasprAgent\nmetadata:\n  name: my-agent\n  labels:\n    kaspr.io/app: my-app\nspec:\n    input:\n        topic: my-topic\n    processor:\n        pipeline:\n            - my-processor\n        operations:\n            - name: my-processor\n              map:\n                python: |\n                    def process(event):\n                    return event"}},"/docs":{"title":"Kaspr Documentation","data":{"":"Kaspr dramatically simplifies the creation of real-time, event-driven applications and microservices. Built as a set of Kubernetes CRDs (Custom Resource Definitions), it provides a straightforward framework for building scalable streaming and event processing systems.Kaspr has a single dependency: Kafka, which serves as the persistence and transport layer for all events processed by the system. While similar to Kafka Streams, Kaspr offers greater flexibility by not being limited to a domain-specific language (DSL). Kaspr is optimized for Kubernetes, offering both ease of use and scalability.","use-cases#Use Cases":"Event driven microservices\nReal-time data integration\nReal-time analytics\nStateful computations\nMaterialized views/cache","quick-start#Quick Start":""}},"/docs/user-guide/agents":{"title":"Agents - Distributed Stream Processors","data":{"what-is-a-kaspragent#What Is a KasprAgent?":"A KasprAgent is a stream processor defined as a Kubernetes custom resource. It listens to incoming event streams from Kafka topics or in-memory channels, applies custom logic using a programmable pipeline of operations, and optionally produces results to output topics, channels, or sinks.KasprAgents provide a fully declarative, Kubernetes-native way to express stream processing applications, making them easy to version, manage, and deploy like any other resource in your cluster.","quickstart#Quickstart":"","create-a-kaspragent#Create a KasprAgent":"A minimal agent can be created by specifying an input topic and a simple mapping processor:\napiVersion: kaspr.io/v1alpha1\nkind: KasprAgent\nmetadata:\n  name: echo-agent\nspec:\n  input:\n    topic:\n      name: demo-input\n  output:\n    topics:\n      - name: demo-output\n  processors:\n    pipeline:\n      - echo\n    operations:\n      - name: echo\n        map:\n          python: |\n            def echo(value):\n                return value\nApply it using:\nkubectl apply -f echo-agent.yaml","components-of-a-kaspragent#Components of a KasprAgent":"","input#Input":"Agents must define their input source. This is either:\nA Kafka topic, defined with name or pattern, and serialization settings.\nAn in-memory channel, useful for internal communication or testing.\nYou can also set declare: true to have the agent auto-create the topic if missing.\ninput:\n  topic:\n    name: my-topic\n    declare: true\n    keySerializer: json\n    valueSerializer: json","input-buffering#Input Buffering":"Agents can buffer multiple input events before processing them as a batch. This is useful for scenarios where processing efficiency improves with larger batches, such as bulk database operations or machine learning inference.\ninput:\n  topic:\n    name: sensor-data\n  take:\n    max: 100           # Process up to 100 events at once\n    within: 5s         # Or process after 5 seconds, whichever comes first\nWhen buffering is enabled, your processor functions receive a list of events instead of individual events:\nprocessors:\n  operations:\n    - name: batch-process\n      map:\n        python: |\n          def process_batch(events):\n              # events is now a list of values\n              processed = []\n              for event in events:\n                  event[\"batch_size\"] = len(events)\n                  processed.append(event)\n              return processed\nBuffering is particularly beneficial for:\nBulk operations: Database inserts, API calls with batch endpoints\nStatistical analysis: Computing aggregates over windows of data\nML inference: Batch prediction for better GPU utilization\nI/O optimization: Reducing network round trips","output#Output":"KasprAgents can emit output to:\nKafka topics, defined with static names or dynamic functions.\nIn-memory channels for internal use.\nCustom sinks defined by Python code\nEach output target can define:\nkeySelector, valueSelector, and optional headersSelector\npredicate for filtering what values to allow to pass through\npartitionSelector for custom partitioning\nack: true for delivery guarantees\nExample:\noutput:\n  topics:\n    - name: my-output-topic\n      keySelector:\n        python: |\n          def get_key(value):\n              return value[\"id\"]\n      predicate:\n        python: |\n          def should_send(value):\n              return \"id\" in value","processors#Processors":"The heart of a KasprAgent is its processors section, which defines the transformation pipeline.A processor pipeline is:\nDeclared as a sequence of named operations\nBacked by user-defined Python map and/or filter functions\nOptional tables can be attached for stateful logic\nExample:\nprocessors:\n  pipeline:\n    - validate\n    - enrich\n  init:\n    python: |\n      def init():\n          print(\"Initializing agent...\")\n  operations:\n    - name: validate\n      filter:\n        python: |\n          def validate(value):\n              return value.get(\"is_valid\", False)\n    - name: enrich\n      map:\n        python: |\n          def enrich(value):\n              value[\"processed\"] = True\n              return value","initialization#Initialization":"The init block lets you define startup logic, load configuration, prepare resources, or validate environment variables.\ninit:\n  python: |\n    import os\n    if \"MY_VAR\" not in os.environ:\n        raise RuntimeError(\"Missing MY_VAR\")","table-access#Table Access":"Agents can reference state tables and use them as inputs to their operations.\ntables:\n  - name: my-table\n    paramName: table\nmap:\n  python: |\n    def enrich(value, table):\n        value[\"status\"] = table.get(value[\"id\"], \"unknown\")\n        return value","partitioning-and-routing#Partitioning and Routing":"Kafka partitioning is automatically leveraged if your input topics are partitioned. You can control output partitioning via partitionSelector.You may also implement repartitioning by emitting records with a newly computed key via keySelector and routing to a new topic.","processing-failures#Processing Failures":"When an agent encounters an exception during event processing, the system maintains exactly-once semantics by acknowledging the source message and not reprocessing it. While this prevents duplicate processing, it raises the question of what happens to failed events.There are several approaches to handling failed events, each with trade-offs:Acknowledgment (Current Behavior)\nThe failed message is acknowledged and marked as complete\nEnsures exactly-once processing semantics\nFailed events are not reprocessed automatically\nRetry Strategies\nRetrying requires stopping topic processing to maintain message ordering\nThe next offset cannot be processed until the failed event is resolved\nMoving events to the \"back of the queue\" breaks topic ordering\nInstance Restart\nCrashing the instance forces human intervention\nNot ideal given the frequency of code errors and unexpected exceptions\nBetter to log errors and notify operations teams for manual replay","explicit-error-handling#Explicit Error Handling":"Agents may emit to dead-letter queues (DLQs) using conditional logic in predicate or return values that match failure conditions.\noutput:\n  topics:\n    - name: dead-letter-topic\n      predicate:\n        python: |\n          def should_send(value):\n              return \"error\" in value","concurrency-and-scaling#Concurrency and Scaling":"KasprAgents scale by deploying multiple KasprApp replicas. Kafka ensures partition-based routing, meaning each message lands on exactly one instance.\nKafka automatically distributes topic partitions across available agent instances using consumer group rebalancing. When you scale agent replicas:\nAdding instances: New agents join the consumer group and Kafka redistributes partitions to balance the load\nRemoving instances: Kafka detects unavailable agents and reassigns their partitions to remaining instances\nPartition assignment: Each partition is consumed by exactly one agent instance at a time, ensuring ordered processing\nThis automatic rebalancing means agents can scale horizontally without manual intervention, with processing automatically redistributed as the cluster size changes."}},"/docs/user-guide/concepts":{"title":"Concepts","data":{"":"This section provides an overview of the concepts that are important to understand when working with Kaspr.","application-app#Application (App)":"An app (KasprApp) is a program that runs all the components of a distributed stream processing application.  It is composed of agents (stream processors), tasks, channels, tables, and web views to perform useful work.\nWe can have multiple instances of an app to distribute a processing and scale in a horizontal manner.An app can be seen as a service in a microservice architecture. It's common to have many different apps, each responsible for a set of functions, that are part of a larger or complex system.\n...","stream#Stream":"A stream is an infinite sequence of events coming from a Kafka topic or channel. In Kaspr, a stream is implicitly created through an (KasprAgent), which manages the stream's lifecycle, determines what enters the stream, and defines how its events are processed.An event serves as a general wrapper for messages. Each event contains references to both the serialized and deserialized versions of the key and value messages, along with additional metadata, such as the message offset.","agent#Agent":"An agent (KasprAgent) is a distributed system that processes events in a stream. Each agent runs within an app, and an app can host multiple agents. An agent consumes data from an input source, such as a Kafka topic or a channel, and performs one or more processing operations on either individual events or batches of events.Streams can be divided among agents either in a round-robin fashion or by partitioning them based on the message key. This determines how the stream is distributed across available agent instances within all app instances. For instance, if the stream's messages are keyed by account ID and the value is a high score, the partitioning ensures that all messages with the same account ID are consistently processed by the same agent instance.Agents are at the core of stream processing in Kaspr, capable of performing a variety of operations, including transformations and aggregations, right out of the box. Additionally, agents can define custom processing logic using arbitrary Python code, providing flexibility for more complex operations.","table#Table":"A (KasprTable) provides durable, fault-tolerant memory for stream processing. While similar to a database, a Table differs in key ways: instead of residing on a remote host and offering a rich query interface, a Table is a simple key-value store embedded directly within an application. This local embedding allows for ultra-fast reads and writes.Each Table is backed by a Kafka topic, often compacted and referred to as a changelog topic. Every record written to a Table is also published to its changelog topic. This design enables the system to rebuild the entire state of the Table in case of a failure, ensuring data consistency and fault tolerance.Internally, a Table leverages an embedded RocksDB database. The data capacity of RocksDB is limited by the disk size of the machine, not its memory, making it suitable for managing large datasets.Tables play a critical role in enabling applications to store state in a fault-tolerant manner, allowing stream processors to perform stateful computations such as aggregations and data enrichments.There are two types of Tables: normal and global.\nNormal:\nA normal Table is distributed across instances of an application, as it is partitioned based on the partitions of the underlying changelog topic. In a multi-instance setup, each application instance holds a subset of the Table's keys. However, in a single-instance setup, a normal Table behaves similarly to a global Table.\nGlobal:\nA global Table, by contrast, provides each application instance with a complete copy of the data. This distinction becomes important when scaling an application to run across multiple instances. Unlike normal Tables, which divide the dataset among instances, global Tables replicate the entire dataset to each instance.\nThis flexibility allows developers to choose the appropriate Table type based on their application's requirements for scalability and data locality.","task#Task":"A task (KasprTask) represents arbitrary work that is performed asynchronously in the background, independent of agents. Tasks can be defined to run as one-time operations, on fixed time intervals, or on a recurring schedule using loops or cron expressions.Tasks operate within an app, and an app can run multiple tasks simultaneously.Some examples of how tasks can be used include:\nPolling external APIs and publishing data to a topic or channel\nReading from a (KasprTable) and performing an action, such as making a POST request to an HTTP endpoint\nTriggering scheduled business processes\nGenerating synthetic data\nTasks provide a flexible way to perform background operations without blocking other processes within the app.\nTasks provide a powerful way to handle asynchronos operations in a kaspr application, enabling a wide variety of background processing needs.","web-view#Web View":"A webview (KasprWebView) connects web-based interactions with stream processing workflows. It allows you to expose your stream processing pipelines as HTTP endpoints, enabling external systems, applications, or users to interact with your data processing logic using standard web requests. By bridging HTTP-based communication with Kaspr's stream processing capabilities, WebViews provide a flexible and scalable way to integrate real-time data processing into web-accessible services.","channel#Channel":"A channel (KasprChannel) is an in-memory buffer or queue used for sending and receiving messages within a local application (process) only. In Kaspr, channels function similarly to Kafka topics, enabling communication between agents within the same app. However, unlike Kafka topics, messages in channels do not persist across application restarts, meaning they are temporary and are lost when the app is restarted."}},"/docs/user-guide/kafka-basics":{"title":"Kafka - Basics you need to know","data":{"":"Kafka is a distributed event streaming platform designed for high-throughput, fault-tolerant, and scalable data processing. It enables applications to publish, subscribe to, and process streams of events (or messages) in real-time. Kafka stores these events in topics, which are partitioned and replicated for reliability.","topics#Topics":"A topic is a logical channel through which data is written and read in a Kafka cluster. Topics are partitioned, meaning the data is split across multiple segments (partitions) to enable parallel processing and scalability. Each partition is ordered, and messages within it are assigned sequential offsets. Topics are also replicated for fault tolerance, ensuring data availability even if a broker fails. Producers write messages to a topic, while consumers read from it, either individually or as part of a consumer group for load balancing. Kafka topics can be configured with retention policies to manage how long messages are stored, making them flexible for real-time and historical data processing.","partitions#Partitions":"A partition is a smaller, ordered subset of a Kafka topic, designed to enable scalability and parallelism in data processing. Each partition is identified by a unique number and stores messages in the order they are produced, with each message assigned a sequential offset. Partitions allow a topic to scale horizontally across multiple brokers, distributing both storage and processing load. Consumers in a consumer group can read from partitions in parallel, ensuring efficient data processing. Partitions also support replication for fault tolerance, with one partition replica designated as the leader to handle all reads and writes, while others act as backups.","offsets#Offsets":"An offset in Kafka is a unique identifier assigned to each message within a topic partition. Offsets ensure messages are stored and retrieved in the exact order they were produced. Consumers use offsets to track their position in the stream, allowing them to resume processing from a specific point if needed. Offsets are specific to a partition and are not shared across partitions, meaning each partition has its own independent sequence. This mechanism provides precise control over message consumption and ensures reliable processing in distributed systems.","consumers#Consumers":"A consumer is a client application that reads and processes messages from Kafka topics. Consumers subscribe to one or more topics and fetch data in sequential order from assigned partitions. They work as part of consumer groups, where each consumer in the group processes messages from a unique set of partitions, enabling parallelism and scalability. A KasprApp is a consumer group. Consumers use offsets to track which messages have been read, allowing them to resume processing from a specific point in case of a failure. This flexibility makes Kafka Consumers ideal for building event-driven and real-time data processing systems.","load-balancing#Load Balancing":"Load balancing and scale out is achieved through consumer groups, where multiple consumers collaboratively process messages from a topic. Each partition in the topic is assigned to only one consumer within the group at a time, ensuring that no two consumers handle the same data. If there are more partitions than consumers, some consumers may process multiple partitions, while if there are more consumers than partitions, some consumers remain idle.When a new consumer joins or leaves the group (or fails), Kafka triggers a rebalance to reassign partitions among the active consumers. This dynamic assignment enables horizontal scaling and fault tolerance. The rebalancing process ensures efficient load distribution, optimizing throughput while maintaining the order of messages within each partition.","log-compaction#Log Compaction":"Log compaction in Kafka is a mechanism that ensures only the most recent value for each unique key in a topic is retained, while older records with the same key are deleted. This process helps reduce storage usage and keeps topics efficient for use cases like maintaining the current state of a system. Compaction occurs in the background, allowing Kafka to store a snapshot of the latest data while retaining older data for keys that don’t have newer updates. Unlike traditional retention, which deletes all messages after a certain time or size threshold, log compaction preserves the latest state indefinitely, ensuring durability and correctness for stateful applications.A KasprTable uses log compaction to ensure table state can be recovered without a large space overhead."}},"/docs/user-guide/patterns":{"title":"Agents Patterns - Common Use Cases","data":{}},"/docs/user-guide/scheduler":{"title":"Kaspr Scheduler","data":{"":"This document provides a detailed explanation of the Kaspr scheduler feature for developers. The scheduler is a core component of the Kaspr stream processing framework and is designed to enable scheduling the delivery of events to Kafka topics at specified times.Below is an in-depth guide to understanding, configuring, and operating the scheduler.","overview#Overview":"A scheduler is built into the KasprApp when the scheduler feature is enabled. It enables clients to schedule messages for future delivery by sending them to an internal Kafka topic. Once enabled, the scheduler sets up required internal topics and components for managing scheduled messages. Its distributed architecture allows horizontal scaling and high-throughput message dispatching.","architecture-and-components#Architecture and Components":"The scheduler is composed of four main components that work together to reliably store, evaluate, and dispatch messages:","timetable#Timetable":"Function:\nActs as a durable, distributed state store (backed by a Kafka topic) where scheduled messages are stored and organized in chronological order.\nKey Points:\nStores messages in a durable manner.\nEvaluates which messages are due for delivery.\nThe timetable is partitioned across KasprApp instances to allow parallel processing.","dispatcher#Dispatcher":"Function:\nResponsible for evaluating the timetable every second and dispatching messages that are due for delivery to their target Kafka topics.\nKey Points:\nProcesses messages chronologically.\nWorks in a distributed environment, leveraging multiple instances for high throughput.\nGuarantees at-least-once delivery.","checkpoint-component#Checkpoint Component":"Function:\neeps track of the dispatcher's progress in processing the timetable. This ensures that after an application restart or failure, the dispatcher resumes from the correct position.\nKey Points:\nProvides fault tolerance.\nEnsures consistent progress and message delivery.","janitor#Janitor":"Function:\nPrunes historical data from the timetable, removing messages that have already been delivered and are no longer needed.\nKey Points:\nPrevents the buildup of outdated messages.\nHelps maintain scheduler performance by reducing state size.","configuration#Configuration":"","enabling-the-scheduler#Enabling the Scheduler":"The scheduler is enabled via the schedulerEnabled configuration on the KasprApp custom resource. When enabled, the following actions occur:\nThe KasprApp deploys an internal scheduler.\nInternal Kafka topics are created:\nschedule-requests for scheduling requests.\nschedule-rejections for handling improperly formatted requests.","topic-configurations#Topic Configurations":"The scheduler relies on the following topics:\nschedule-requests:\nClients send messages here to request future delivery. The message must include:\nKey and Value: The content of the message to be scheduled.\nHeaders:\nx-scheduler-deliver-to: The destination topic for the scheduled message.\nx-scheduler-deliver-at: An ISO format UTC timestamp specifying when the message should be delivered.\nschedule-rejections:\nIf a message is missing the required headers or has a malformed timestamp, it is forwarded here with details about the error.","performance-tuning#Performance Tuning":"The scheduler is designed to handle both low and high volumes of scheduled messages:\nHorizontal Scaling:\nIncrease the number of KasprApp replicas to distribute the timetable and parallelize dispatching.\nPartitioning:\nAdjust the number of partitions for the scheduler topics using the schedulerTopicPartitions configuration. More partitions allow for higher throughput by enabling parallel processing. Increase the number of KasprApp replicas to leverage additional partitions.","message-scheduling-workflow#Message Scheduling Workflow":"","scheduling-requests#Scheduling Requests":"Sending a Request:\nClients publish a message to the schedule-requests Kafka topic.\nThe message includes:\nThe desired key and value.\nTwo critical headers:\nx-scheduler-deliver-to: Specifies the destination topic.\nx-scheduler-deliver-at: Specifies the delivery time in ISO UTC format.\nProcessing the Request:\nThe scheduler stores the message in the timetable.\nWhen the scheduled timestamp is reached, the dispatcher evaluates the timetable and dispatches the message to the target Kafka topic.","handling-invalid-requests#Handling Invalid Requests":"Invalid or Malformed Messages:\nIf the required headers are missing or the timestamp is malformed, the scheduler forwards the message to the schedule-rejections topic.\nThe rejection includes details on why the scheduling request failed, enabling clients to debug or correct the issue.","immediate-dispatch-for-past-timestamps#Immediate Dispatch for Past Timestamps":"Delivery of Past-Dated Messages:\nIf a message is sent with a delivery timestamp in the past, it is delivered immediately.\nThere is a configurable threshold (schedulerDiscardOldMessageThresholdSeconds) that determines if a message is too old. Messages older than this threshold are not dispatched.","performance-considerations#Performance Considerations":"Throughput vs. Instantaneous Delivery:\nThe scheduler can handle dispatching millions of messages at any given time.\nThe dispatch process ensures that all messages for a specific timestamp are processed before moving on to the next.\nFor extremely high message volumes, running multiple instances of KasprApp is recommended to distribute the load across the distributed timetable.\nScaling Strategy:\nTune the number of replicas and scheduler topic partitions to match the expected throughput.\nMonitor performance metrics to ensure that the scheduler keeps up with the message volume.","limits-and-caveats#Limits and Caveats":"Order Guarantee:\nThe scheduler does not guarantee the order of messages delivered for a given timestamp. It only guarantees that messages are dispatched in accordance with their scheduled delivery time.\nNo Message Unscheduling:\nOnce a message is scheduled, there is no facility to unschedule (delete) it.\nDestination Topic Existence:\nThe scheduler assumes that the destination topic (as specified in x-scheduler-deliver-to) exists. If it does not, the scheduler will stall dispatching messages until the topic is created.","best-practices#Best Practices":"Dedicated Scheduler Instances:\nFor production or high-throughput use cases, consider deploying dedicated KasprApp for scheduling. This ensures that the scheduler is not burdened by additional processing logic from KasprAgents.\nPre- and Post-Processing:\nDeploy separate KasprApps if there is a need to pre-process messages before scheduling or to post-process messages after they have been dispatched.\nMonitoring:\nRegularly monitor scheduler metrics to detect performance bottlenecks or errors.","monitoring-and-metrics#Monitoring and Metrics":"The scheduler exposes operational metrics that help track its performance and health:\nGrafana Dashboard:\nA pre-configured Grafana dashboard is available for visualizing scheduler metrics."}},"/":{"title":"Kaspr – Event Streaming for Kubernetes","data":{}}}